import scala.util.Random
import annotation.tailrec
import math.log
/* pi is an M length array of unnormalized initial state probabilities
 * T is an MxM matrix of state transition probabilities (Transition Matrix)
 * A is an MxO matrix of emission probabilities where O is the number
 *   of possible emission possibilities in any state (Action Matrix)
 *
 * PRCONDITIONS:
 *   T must be square
 *   A must have the same number of rows as T
 *
 * Probability matrices may be unnormalized
 */
class Hmm(val pi: Seq[Double], val T: Array[Array[Double]],
	  val A:  Array[Array[Double]]) {

  require(T.length == T(0).length) // Assume all rows of T are T(0).length
  require(A.length == T.length)

  val rand = new Random()
  val numStates  = T.length
  val numActions = A.length

  /* Generate an observation sequence from this Hmm */
  def genObsSeq(steps:Int): List[Int] = {

    def tailRecGenObs(steps:  Int,
		      currState: Int = inverseSample(pi.toList),
		      obsSeq: List[Int] = List()): List[Int] = steps match {
      case 0     => obsSeq.reverse
      case steps => tailRecGenObs(steps-1,
				  inverseSample(T(currState).toList),
				  inverseSample(A(currState).toList) :: obsSeq)
    }
    tailRecGenObs(steps)
  }

  /* This function implements the forward algorithm (given a set of
   * observations, it returns the log probability of that set of observations
   * having come from THIS Hmm).
   *
   * PRECONDITIONS:
   *   This Hmm must have an A and a T matrix
   *   all of the observations should be valid (could have possibly been
   *   generated by this Hmm
   */
  def forward(obsSeq: Seq[Int]): Double = {

    def fwd_TR(obsSeq: Seq[Int], trellis: Seq[Double] = pi,
	       logSum: Double = 0.0): Double = obsSeq match {
      case x::xs => fwd_TR(xs,
			   logFwdStep(trellis.toList, x)._1,
			   logSum + log(trellis.sum))
      case _     => log(trellis.sum) + logSum
    }
    fwd_TR(obsSeq)
  }

  /* alernate implementation of fowrad algorithm using a fold. I'm not sure
   * I like this better */
  def fwd(obsSeq: Seq[Int]): Double = {
    val (trellis, scale) = obsSeq.foldLeft((pi, 0.0))(
      (state: (Seq[Double], Double), obs: Int) =>
	logFwdStepWithScale(state ,obs))
    log(trellis.sum) + scale
  }

  /* Get a column of any matrix stored in rows */
  private def column[T, M[_]](matrix: M[M[T]], col: Int)
  (implicit v1: M[M[T]] => Seq[M[T]], v2: M[T] => Seq[T]): Seq[T] = {
    matrix.map{ x => x.toList(col) }
  }

  /* FUTURE WORK: Get this working with breeze (as well as the previous)
   *
   * This is just a matrix vector multiply: pre-multiply the current values
   * in the trellis by the transpose of the transition matrix, and then a
   * element wise product of the probabilities of being in a particular
   * state times the probability of emitting a vertain token
   *
   * PRECONDITION: the trellis passed in represents the probabilities of
   * being in a certain state and having emitted a certain token
   *
   * POSTCONDITION: the output the probabilities of being in the next state
   * and having emitted obs
   */
  private def fwdStep(trellis: List[Double], obs: Int): List[Double] = {
    trellis.zipWithIndex.map{
      case (_,idx) => dotProd(trellis,column(T,idx)) * A(idx)(obs)
    }
  }

/* forward step with log scaling */
  private def logFwdStepWithScale(state: (Seq[Double], Double),
				  obs:   Int) :
  (Seq[Double], Double) = {
    val (trellis, scale) = state
    val s = trellis.sum
    (fwdStep(trellis.toList.map(_ / s),obs), scale + log(s))
  }

  /* forward step with log scaling */
  private def logFwdStep(trellis: Seq[Double], obs:Int):
  (Seq[Double], Double) = {
    val s = trellis.sum
    (fwdStep(trellis.toList.map(_ / s),obs), log(s))
  }

  private def dotProd(v1: Seq[Double], v2: Seq[Double]): Double = {
    v1.zip(v2).map{ case (x1, x2) => x1 * x2 }.reduceLeft(_ + _)
  }

  /* take the elem wise log product of v1 and v2 and return the max product
   * tupled with the corresponding index */
  private def logMaxProd(v1: Seq[Double], v2: Seq[Double]): (Double, Int) = {
    v1.zipWithIndex.map{
      case(x, i) => (log(x) + log(v2(i)), i)
    }.sortBy(_._1).last
  }

  /* calculate the maximum transition probably to each state give a set of
   * probabilities (of being in each state). Return the probability after
   * transitioning and the state from which the transition was made */
  private def maxTransitionProb(v: List[Double]): List[(Double, Int)] = {
   (0 to (T.length-1)).map(ind => logMaxProd(v, column(T, ind))).toList
  }

  /* Implements the Viterbi algorithm for Hmms.  Given an observation sequence
   * and an Hmm, calculate the most likely sequence of states to have
   * generated the sequence
   *
   * PRECONDITION: All values in obsSeq are valid observations (i.e. every
   * observation is an integer less than the total number of distinct
   * observations.
   *
   * Invariant: after each iteration, each column in history holds the
   * sequence of highest probability transition states that end in a
   * particular state with respect to the observation sequence
   * Returns a sequence of ints corresponding to the sequence of most likely
   * states to have produced this sequence
   */
  def decode(obsSeq: Seq[Int]): Seq[Int] = {

    def viterbi(obs:     Seq[Int],
		lhoods:  List[Double],
		history: List[List[Int]]): Seq[Int] = obs match {
      case x::xs => {
	val (newLhoods, nextSteps) = maxTransitionProb(lhoods).unzip
	viterbi(
	  xs,
	  newLhoods.zip(column(A, x)).map{ case(a,b) => log(a) + log(b) },
	  history :+ nextSteps
	)
      }
      case _ => column(history, lhoods.zipWithIndex.sortBy(_._1).last._2)
    }

    viterbi(obsSeq, pi.toList, List(List()))
  }

  /* TODO: 1) Write better documentation
   *       2) Add smoothing
   *
   * Given an observation sequence and the set of hidden states that
   * generated the sequence, learn the initial state probabilities,
   * the transition matrix and the observation matrix
   */
   def learn(obsSeq: Seq[Int], stateSeq: Seq[Int]):
  (Array[Double], Array[Array[Double]], Array[Array[Double]]) = {
     val numStates = stateSeq.max
     val numObs    = obsSeq.max

     var pi = new Array[Double](numStates)
     var T  = new Array[Array[Double]](numStates)
     var O  = new Array[Array[Double]](numStates)

     for (i <- 0 to numStates) {
       T(i) = new Array[Double](numStates)
       O(i) = new Array[Double](numObs)
     }

     /* Count the number of times every state transition has been made */
     (stateSeq.init).zip(stateSeq.tail).map({ case (t1, t2) => T(t1)(t2) += 1})

     /* Count the number of times you observe each output from each state */
     obsSeq.zip(obsSeq).map({case (o1, o2) => O(o1)(o2) += 1})
     stateSeq.map(s => pi(s) += 1)

     /* Normalize rows to makes the counts into probabilities */
     (normalize(pi), T.map(normalize(_)), O.map(normalize(_)))
   }

  /*  Implements inverse transform sampling from an unnormalized distribution
   *  return value: random index into dist chosen proportional to the weight
   *  stored in that bin (think of dist as an unnormalized multinomial)
   */
  private def inverseSample(dist: List[Double]): Int = {
    val sample = rand.nextDouble()
    dist.scanLeft(0.0)(_+_).tail.zipWithIndex.filter(sample <= _._1).head._2
  }

  private def normalize(row: Array[Double]): Array[Double] = {
    val total = row.sum
    row.map(e => e / total)
  }
}
