import scala.util.Random
/* pi is an M length array of unnormalized initial state probabilities
 * T is an MxM matrix of state transition probabilities (Transition Matrix)
 * A is an MxO matrix of emission probabilities where O is the number
 *   of possible emission possibilities in any state (Action Matrix)
 *
 * PRCONDITIONS:
 *   T must be square
 *   A must have the same number of rows as T
 *
 * Probability matrices may be unnormalized
 */
class Hmm(val pi: Array[Double], val T: Array[Array[Double]],
	  val A:  Array[Array[Double]]) {

  require(T.length == T(0).length) // Assume all rows of T are T(0).length
  require(A.length == T.length)

  val rand = new Random()
  val numStates  = T.length
  val numActions = A.length

  /* Generate an observation sequence from this Hmm
   */
  def genObsSeq(steps: Int): Seq[Int] = {
    val observations = new Array[Int](steps)

    var step = 0
    var currState = inverseSample(pi)
    while (step < steps) {
      observations(step) = inverseSample(A(currState))
      currState = inverseSample(T(currState))
      step += 1
    }

    return observations
  }

  /* Functional Version */
  def genObsSeq_func(steps: Int, currState: Int = inverseSample(pi),
		     obsSeq: List[Int] = List()): List[Int] = steps match {
    case 0     => obsSeq.reverse
    case steps => genObsSeq_func(steps-1, inverseSample(T(currState)),
				 inverseSample(A(currState)) :: obsSeq)
  }

  /* FUTURE WORK: 1) get rid of while loops
   *
   * This function implements the forward algorithm (given a set of
   * observations, it returns the log probability of that set of observations
   * having come from THIS Hmm).
   *
   * PRECONDITIONS:
   *   This Hmm must have an A and a T matrix
   *   all of the observations should be valid (could have possibly been
   *     generated by this Hmm
   */
  def forward(obsSeq: Seq[Int]): Double = {
    var prevTrellis = new Array[Double](numStates)
    var currTrellis = new Array[Double](numStates)
    var alphas      = new Array[Double](numStates) // stores prob of being in
						   // state i after N steps
    var obsItr    = 0
    var stateItr  = 0   // generic itr
    var currState = 0
    while(stateItr < numStates) {        // Initialize
      prevTrellis(stateItr) = pi(stateItr) * A(stateItr)(obsSeq(obsItr));
      stateItr = stateItr + 1
    }

    // scale probs to prevent underflow
    var alphaSum = 0.0  // stores the sum of alpha(i)'s; used for scaling
    var logScale = 0.0  // total log scaling so far

    alphaSum    = prevTrellis.sum
    prevTrellis = prevTrellis.map( _ / alphaSum)
    logScale   += math.log(alphaSum)

    obsItr    = 1
    while (obsItr < obsSeq.length) {

      currState = 0
      while (currState < numStates) {

	alphas(currState) = 0.0
	stateItr = 0
	while (stateItr < numStates) {
	  // I should replace the line below with a dot product
	  alphas(currState) = alphas(currState) + prevTrellis(stateItr) *
			      T(stateItr)(currState)
	  stateItr += 1
	}

	alphas(currState) = alphas(currState) * A(currState)(obsSeq(obsItr))
	currState += 1
      }

      alphaSum  = alphas.sum
      currState = 0
      while(currState < numStates) {
	currTrellis(currState) = alphas(currState) / alphaSum  // scaling
	logScale  += math.log(alphaSum)
	currState += 1
      }

      // NOTE: at this point, currTrellis(i) holds the SCALED probability of
      //       being in state i given the first obsIter tokens in obsSeq
      stateItr = 0
      while (stateItr < numStates) {
	prevTrellis(stateItr) = currTrellis(stateItr)
	stateItr = stateItr + 1
      }
      obsItr = obsItr + 1
    }

    stateItr     = 0
    var sumProb  = 0.0
    while (stateItr < numStates){
      sumProb += currTrellis(stateItr)
      stateItr = stateItr + 1
    }

    // Now, reset scaling (at each step we multiply by
    return math.log(sumProb) + logScale
  }

  /* Just use Scalala */
  private def column(M: Array[Array[Double]], n: Int, c: List[Double] = List(),
		     i: Int = 0): List[Double] = {
    if (i != M.length) column(M, n, M(i)(n)::c, i+1) else c.reverse
  }

  /* This is just a matrix vector multiply: pre-multiply the current values
   * in the trellis by the transpose of the transition matrix
   */
  private def fwdStep(trellis: List[Double]): List[Double] = {
    trellis.zipWithIndex.map{ e: (Double,Int) =>
				  dotProd(trellis,column(T,e._2))}
  }

  private def dotProd(v1: List[Double], v2: List[Double]): Double = {
    v1.zip(v2).map{ e:(Double, Double) => e._1 * e._2 }.reduceLeft(_ + _)
  }

  /* FUTURE WORK: 1) Better Names
   *              2) Make this more functional
   *
   * Implements the Viterbi algorithm for Hmms.  Given an observation sequence
   * and an Hmm, calculate the most likely sequence of states to have
   * generated the sequence
   *
   * PRECONDITION: All values in obsSeq are valid observations (i.e. every
   * observation is an integer less than the total number of distinct
   * observations.
   *
   * Returns a sequence of ints corresponding to the sequence of most likely
   * states to have produced this sequence
   */
  def decode(obsSeq: Seq[Int]): Seq[Int] = {
    var prevTrellis = new Array[Double](numStates)
    var currTrellis = new Array[Double](numStates)
    var probOfState = new Array[Double](numStates)
    var viterbiPath = new Array[Array[Int]](numStates)  //optimal path

    var obsItr = 0
    var currState = 0
    var stateItr  = 0
    while (stateItr < numStates) {
      viterbiPath(stateItr) = new Array[Int](obsSeq.length)
      prevTrellis(stateItr) = math.log(pi(stateItr)) +
			      math.log(A(stateItr)(obsSeq(obsItr)))
      stateItr += 1
    }

    obsItr = 1
    while (obsItr < obsSeq.length) {

      currState = 0
      while (currState < numStates) {

	stateItr = 0
	while (stateItr < numStates) {
	  probOfState(stateItr) = math.log(prevTrellis(stateItr)) +
				  math.log(T(stateItr)(currState))
	  stateItr += 1
	}

	currTrellis(currState) = math.log(probOfState.max) +
				 math.log(A(currState)(obsSeq(obsItr)))

	// get index of largest probability
	viterbiPath(currState)(obsItr) = probOfState.zipWithIndex.max._2
	currState += 1
      }

      stateItr = 0
      while (stateItr < numStates) {
	prevTrellis(stateItr) = currTrellis(stateItr)
	stateItr += 1
      }
      obsItr += 1
    }

    var hiddenStateSeq = new Array[Int](obsSeq.length)
    var maxProbIndex   = currTrellis.zipWithIndex.max._2
    obsItr = obsSeq.length - 1
    while (obsItr >= 0) {
      hiddenStateSeq(obsItr) = maxProbIndex
      maxProbIndex = viterbiPath(maxProbIndex)(obsItr)
      obsItr -= 1
    }

    return hiddenStateSeq
  }

  /* TODO: 1) Write better documentation
   *       2) Add smoothing
   *
   * Given an observation sequence and the set of hidden states that
   * generated the sequence, learn the initial state probabilities,
   * the transition matrix and the observation matrix
   */
   def learn(obsSeq: Seq[Int], stateSeq: Seq[Int]): (Array[Double], Array[Array[Double]], Array[Array[Double]]) = {
     val numStates = stateSeq.max
     val numObs    = obsSeq.max

     var pi = new Array[Double](numStates)
     var T  = new Array[Array[Double]](numStates)
     var O  = new Array[Array[Double]](numStates)

     for (i <- 0 to numStates) {
       T(i) = new Array[Double](numStates)
       O(i) = new Array[Double](numObs)
     }

     /* Count the number of times every state transition has been made */
     (stateSeq.init).zip(stateSeq.tail).map(pair => T(pair._1)(pair._2) += 1)

     /* Count the number of times you observe each output from each state */
     obsSeq.zip(obsSeq).map(pair => O(pair._1)(pair._2) += 1)
     stateSeq.map(s => pi(s) += 1)

     /* Normalize rows to makes the counts into probabilities */
     T.map(row => normalize(row))
     O.map(row => normalize(row))
     pi = normalize(pi)

     return (pi, T, O)
  }

  /* Implemenmts inverse transform sampling from an unnormalized distribution
   *  return value: random index into dist chosen proportional to the weight
   *  stored in that bin (think of dist as an unnormalized multinomial)
   */
  private def inverseSample(dist: Array[Double]): Int = {
    var sum    = dist.sum
    var prev   = 0.0
    val sample = rand.nextDouble() * sum     // rand is from class
    val dSize  = dist.length

    var i = 0
    while(i < dSize) {
      prev += dist(i)
      if (sample <= prev) {
	return i
      }
      i += 1
    }
    return dSize  // Error!!
  }

  private def normalize(row: Array[Double]): Array[Double] = {
    val total = row.sum
    row.map(e => e / total)
  }

  // Functional version
  private def inverseSample_func(dist: List[Double]): Int = {
    val sample = rand.nextDouble()
    dist.scanLeft(0.0)(_+_).zipWithIndex.filter(sample <= _._1).head._2
  }
}
